# General Parameters, see comment for each definition
# can be gbtree or gblinear
booster = gbtree 
# choose logistic regression loss function for binary classification
objective = binary:logistic

# Tree Booster Parameters
# step size shrinkage
eta = 0.3 
# minimum loss reduction required to make a further partition
gamma = 0.5
# minimum sum of instance weight(hessian) needed in a child
min_child_weight = 1 
# maximum depth of a tree
max_depth = 6 

# Task Parameters
# the number of round to do boosting
num_round = 2
# 0 means do not save any model except the final round model
save_period = 0 
# The path of training data
data = "libsvm_train_site.txt" 
# data = "libsvm_train_app.txt" 
# The path of validation data, used to monitor training process, here [test] sets name of the validation set
# eval[test] = "agaricus.txt.test" 
# The path of test data 
test:data = "libsvm_test_site.txt"
# test:data = "libsvm_test_app.txt"

eval_metric = logloss
seed = 888
model_out = "GBTR_D8_01.model"
name_pred = "GBTR_D8_01.txt"
subsample = 1
colsample_bytree = 1